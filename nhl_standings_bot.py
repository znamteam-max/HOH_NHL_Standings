import os
import sys
import json
import datetime as dt
from pathlib import Path
from zoneinfo import ZoneInfo
from html import escape
from typing import Dict, List, Optional, Any
import re

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ====== Telegram ======
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID")

TZ = ZoneInfo("Europe/Helsinki")
DATE_FMT = "%d %b %Y"

USER_AGENT = (
    "NHL-Standings-Bot/1.1 "
    "(+https://site.api.espn.com/apis/v2/; +https://site.web.api.espn.com/apis/v2/)"
)

# ====== –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥ (ESPN –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã) ======
RU_BY_ABBR: Dict[str, str] = {
    # Atlantic
    "BOS": "–ë–æ—Å—Ç–æ–Ω –ë—Ä—é–∏–Ω–∑",
    "BUF": "–ë–∞—Ñ—Ñ–∞–ª–æ –°—ç–π–±—Ä–∑",
    "DET": "–î–µ—Ç—Ä–æ–π—Ç –†–µ–¥ –£–∏–Ω–≥–∑",
    "FLA": "–§–ª–æ—Ä–∏–¥–∞ –ü–∞–Ω—Ç–µ—Ä–∑",
    "MTL": "–ú–æ–Ω—Ä–µ–∞–ª—å –ö–∞–Ω–∞–¥–∏–µ–Ω—Å",
    "OTT": "–û—Ç—Ç–∞–≤–∞ –°–µ–Ω–∞—Ç–æ—Ä–∑",
    "TBL": "–¢–∞–º–ø–∞-–ë—ç–π –õ–∞–π—Ç–Ω–∏–Ω–≥",
    "TOR": "–¢–æ—Ä–æ–Ω—Ç–æ –ú—ç–π–ø–ª –õ–∏—Ñ—Å",
    # Metropolitan
    "CAR": "–ö–∞—Ä–æ–ª–∏–Ω–∞ –•–∞—Ä—Ä–∏–∫–µ–π–Ω–∑",
    "CBJ": "–ö–æ–ª–∞–º–±—É—Å –ë–ª—é –î–∂–µ–∫–µ—Ç—Å",
    "NJD": "–ù—å—é-–î–∂–µ—Ä—Å–∏ –î–µ–≤–∏–ª–∑",
    "NYI": "–ù—å—é-–ô–æ—Ä–∫ –ê–π–ª–µ–Ω–¥–µ—Ä—Å",
    "NYR": "–ù—å—é-–ô–æ—Ä–∫ –†–µ–π–Ω–¥–∂–µ—Ä—Å",
    "PHI": "–§–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è –§–ª–∞–π–µ—Ä–∑",
    "PIT": "–ü–∏—Ç—Ç—Å–±—É—Ä–≥ –ü–∏–Ω–≥–≤–∏–Ω–∑",
    "WSH": "–í–∞—à–∏–Ω–≥—Ç–æ–Ω –ö—ç–ø–∏—Ç–∞–ª–∑",
    # Central
    "ARI": "–ê—Ä–∏–∑–æ–Ω–∞ –ö–æ–π–æ—Ç–∏—Å",   # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    "CHI": "–ß–∏–∫–∞–≥–æ –ë–ª—ç–∫—Ö–æ–∫—Å",
    "COL": "–ö–æ–ª–æ—Ä–∞–¥–æ –≠–≤–µ–ª–∞–Ω—à",
    "DAL": "–î–∞–ª–ª–∞—Å –°—Ç–∞—Ä–∑",
    "MIN": "–ú–∏–Ω–Ω–µ—Å–æ—Ç–∞ –£–∞–π–ª–¥",
    "NSH": "–ù—ç—à–≤–∏–ª–ª –ü—Ä–µ–¥–∞—Ç–æ—Ä–∑",
    "STL": "–°–µ–Ω—Ç-–õ—É–∏—Å –ë–ª—é–∑",
    "WPG": "–í–∏–Ω–Ω–∏–ø–µ–≥ –î–∂–µ—Ç—Å",
    # Utah (–≤–∞—Ä–∏–∞–Ω—Ç—ã —É ESPN –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ)
    "UTH": "–Æ—Ç–∞ –ú–∞–º–º–æ—Ç—Å",
    "UTA": "–Æ—Ç–∞ –ú–∞–º–º–æ—Ç—Å",
    "UTAH": "–Æ—Ç–∞ –ú–∞–º–º–æ—Ç—Å",
    "UHC": "–Æ—Ç–∞ –ú–∞–º–º–æ—Ç—Å",
    # Pacific
    "ANA": "–ê–Ω–∞—Ö–∞–π–º –î–∞–∫—Å",
    "CGY": "–ö–∞–ª–≥–∞—Ä–∏ –§–ª—ç–π–º–∑",
    "EDM": "–≠–¥–º–æ–Ω—Ç–æ–Ω –û–π–ª–µ—Ä–∑",
    "LAK": "–õ–æ—Å-–ê–Ω–¥–∂–µ–ª–µ—Å –ö–∏–Ω–≥–∑",
    "SEA": "–°–∏—ç—Ç–ª –ö—Ä–∞–∫–µ–Ω",
    "SJS": "–°–∞–Ω-–•–æ—Å–µ –®–∞—Ä–∫—Å",
    "VAN": "–í–∞–Ω–∫—É–≤–µ—Ä –ö—ç–Ω–∞–∫—Å",
    "VGK": "–í–µ–≥–∞—Å –ì–æ–ª–¥–µ–Ω –ù–∞–π—Ç—Å",
}

# –∫–æ—Ä–æ—Ç–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä
VARIANT_TO_ESPN_ABBR = {
    "TB": "TBL",
    "LA": "LAK",
}

DIV_RU = {
    "Atlantic": "–ê—Ç–ª–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –¥–∏–≤–∏–∑–∏–æ–Ω",
    "Metropolitan": "–°—Ç–æ–ª–∏—á–Ω—ã–π –¥–∏–≤–∏–∑–∏–æ–Ω",
    "Central": "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –¥–∏–≤–∏–∑–∏–æ–Ω",
    "Pacific": "–¢–∏—Ö–æ–æ–∫–µ–∞–Ω—Å–∫–∏–π –¥–∏–≤–∏–∑–∏–æ–Ω",
}

CONF_DIV_ORDER = {
    "east": ["Atlantic", "Metropolitan"],
    "west": ["Central", "Pacific"],
}

# ====== –ø—É—Ç—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è ¬´–≤—á–µ—Ä–∞—à–Ω–∏—Ö¬ª –ø–æ–∑–∏—Ü–∏–π ======
DATA_DIR = Path("data")
DATA_DIR.mkdir(parents=True, exist_ok=True)
PREV_FILE = DATA_DIR / "nhl_prev_positions.json"

# ====== HTTP —Å —Ä–µ—Ç—Ä–∞—è–º–∏ ======
def make_session() -> requests.Session:
    s = requests.Session()
    retries = Retry(
        total=6, connect=6, read=6,
        backoff_factor=0.7,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"],
        raise_on_status=False,
    )
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({"User-Agent": USER_AGENT})
    return s

SESSION = make_session()

# ====== —É—Ç–∏–ª–∏—Ç—ã ======
def normalize_abbr(abbr: str) -> str:
    a = (abbr or "").upper()
    return VARIANT_TO_ESPN_ABBR.get(a, a)

def arrow(delta_places: Optional[int]) -> str:
    if delta_places is None:
        return "‚ö™Ô∏é="
    if delta_places > 0:
        return f"üü¢‚ñ≤+{delta_places}"
    if delta_places < 0:
        return f"üî¥‚ñº{abs(delta_places)}"
    return "‚ö™Ô∏é="

def _get_json(url: str, params: dict | None = None) -> dict:
    try:
        r = SESSION.get(url, params=params or {}, timeout=30)
        if r.status_code != 200:
            return {}
        return r.json()
    except Exception:
        return {}

def load_prev_positions() -> Dict[str, Dict[str, Dict[str, int]]]:
    """
    {"date":"YYYY-MM-DD",
     "divisions": {
        "Atlantic": {"BOS":1,...},
        "Metropolitan": {...},
        "Central": {...},
        "Pacific": {...}
     }}
    """
    if not PREV_FILE.exists():
        return {"date": "", "divisions": {}}
    try:
        with PREV_FILE.open("r", encoding="utf-8") as f:
            j = json.load(f)
        return {
            "date": j.get("date") or "",
            "divisions": j.get("divisions") or {}
        }
    except Exception:
        return {"date": "", "divisions": {}}

def save_current_as_prev(today: dt.date, by_division: Dict[str, List[Dict]]) -> None:
    """
    by_division: {"Atlantic":[{abbr,rank,...}], ...}
    """
    div_map: Dict[str, Dict[str, int]] = {}
    for div_name, rows in by_division.items():
        div_map[div_name] = {r["abbr"]: r["rank"] for r in rows}
    payload = {"date": today.isoformat(), "divisions": div_map}
    with PREV_FILE.open("w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

# ====== ESPN NHL standings (JSON, division level) ======
def _gather_division_entries(node: Any, acc: Dict[str, List[dict]]) -> None:
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º JSON –∏ —Å–æ–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏, –≥–¥–µ:
      - –µ—Å—Ç—å –ø–æ–ª–µ name/shortName/abbreviation —Å –∏–º–µ–Ω–µ–º –¥–∏–≤–∏–∑–∏–æ–Ω–∞
      - –∏ –≤–Ω—É—Ç—Ä–∏ –µ—Å—Ç—å standings.entries
    """
    if isinstance(node, dict):
        name = (node.get("name") or node.get("shortName") or node.get("abbreviation") or "")
        lname = name.lower()
        is_div = any(k in lname for k in ("atlantic", "metropolitan", "central", "pacific"))
        st = node.get("standings")
        if is_div and isinstance(st, dict) and isinstance(st.get("entries"), list) and st["entries"]:
            key = (
                "Atlantic" if "atlantic" in lname else
                "Metropolitan" if "metropolitan" in lname else
                "Central" if "central" in lname else
                "Pacific" if "pacific" in lname else None
            )
            if key:
                acc[key] = st["entries"]
        # –ø—Ä–æ–¥–æ–ª–∂–∏–º —É–≥–ª—É–±–ª—è—Ç—å—Å—è
        for v in node.values():
            _gather_division_entries(v, acc)
    elif isinstance(node, list):
        for v in node:
            _gather_division_entries(v, acc)

def _stats_to_map(stats_list: List[dict]) -> Dict[str, Any]:
    m: Dict[str, Any] = {}
    for s in stats_list or []:
        name = s.get("name") or s.get("abbreviation") or s.get("shortDisplayName")
        if not name:
            continue
        m[name] = s.get("value", s.get("displayValue"))
    return m

def _entries_to_rows(entries: List[dict]) -> List[Dict]:
    rows: List[Dict] = []
    for e in entries:
        team = e.get("team") or {}
        display = team.get("displayName") or team.get("name") or ""
        abbr = normalize_abbr(team.get("abbreviation") or team.get("shortDisplayName") or display)

        stats = _stats_to_map(e.get("stats") or [])
        gp = int(stats.get("gamesPlayed") or stats.get("gp") or 0)
        w  = int(stats.get("wins") or 0)
        l  = int(stats.get("losses") or 0)
        ot = int(stats.get("otLosses") or stats.get("otl") or 0)
        pts = int(stats.get("points") or stats.get("pts") or (w*2 + ot))

        rows.append({"team": display, "abbr": abbr, "gp": gp, "w": w, "l": l, "ot": ot, "pts": pts})

    rows.sort(key=lambda x: (-x["pts"], -x["w"], x["team"]))
    for i, r in enumerate(rows, 1):
        r["rank"] = i
    return rows

def fetch_nhl_standings_by_division() -> Dict[str, Dict[str, List[Dict]]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      {
        "east": {"Atlantic":[...], "Metropolitan":[...]},
        "west": {"Central":[...], "Pacific":[...]}
      }
    """
    # –∫–ª—é—á: level=3 -> –¥–∏–≤–∏–∑–∏–æ–Ω–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞; —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ—Å–µ–≤—É/–æ—á–∫–∞–º/–∏–≥—Ä–∞–º/ROW
    params = {
        "region": "us",
        "lang": "en",
        "contentorigin": "espn",
        "type": "0",
        "level": "3",
        "sort": "playoffseed:asc,points:desc,gamesplayed:asc,rotwins:desc",
    }
    candidates = [
        "https://site.api.espn.com/apis/v2/sports/hockey/nhl/standings",
        "https://site.web.api.espn.com/apis/v2/sports/hockey/nhl/standings",
    ]
    data = {}
    for u in candidates:
        data = _get_json(u, params=params)
        if data:
            break
    if not data:
        return {"east": {}, "west": {}}

    divisions_raw: Dict[str, List[dict]] = {}
    _gather_division_entries(data, divisions_raw)

    # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –∏–Ω–æ–≥–¥–∞ –¥–∏–≤–∏–∑–∏–æ–Ω—ã –º–æ–≥—É—Ç –ª–µ–∂–∞—Ç—å –æ–¥–Ω–∏–º –º–∞—Å—Å–∏–≤–æ–º –≤ "children"
    if not divisions_raw and "children" in data:
        for ch in data.get("children") or []:
            _gather_division_entries(ch, divisions_raw)

    # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º entries -> rows
    div_rows: Dict[str, List[Dict]] = {k: _entries_to_rows(v) for k, v in divisions_raw.items()}

    east = {k: div_rows.get(k, []) for k in ("Atlantic", "Metropolitan")}
    west = {k: div_rows.get(k, []) for k in ("Central", "Pacific")}
    return {"east": east, "west": west}

# ====== —Ç—Ä–µ–Ω–¥ –≤–Ω—É—Ç—Ä–∏ –¥–∏–≤–∏–∑–∏–æ–Ω–æ–≤ ======
def attach_trend_div(rows: List[Dict], y_positions: Dict[str, int]) -> List[Dict]:
    ranked = sorted(rows, key=lambda x: (-x["pts"], -x["w"], x["team"]))
    for i, r in enumerate(ranked, 1):
        r["rank"] = i
        y = y_positions.get(r["abbr"])
        r["delta_places"] = None if y is None else (y - i)
    return ranked

# ====== —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ======
_TAG_RE = re.compile(r"<[^>]+>")

def fmt_division(title: str, rows: List[Dict]) -> str:
    """
    –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫:
      1  üü¢‚ñ≤+1  –ë–æ—Å—Ç–æ–Ω –ë—Ä—é–∏–Ω–∑   6   4   1   1    9
         (–º–µ—Å—Ç–æ, —Å—Ç—Ä–µ–ª–∫–∞) (–†–£–° –Ω–∞–∑–≤–∞–Ω–∏–µ) (GP) (W) (L) (OT) (PTS)
    –ü–æ—Å–ª–µ 3-–≥–æ –º–µ—Å—Ç–∞ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å '-------'.
    """
    out = [f"<b>{escape(title)}</b>"]
    for r in rows:
        line = (
            f"{r['rank']:>2} {arrow(r.get('delta_places')):>4}  "
            f"{escape(RU_BY_ABBR.get(r['abbr'], r['team']))}  "
            f"{r['gp']:>2}  {r['w']:>2}  {r['l']:>2}  {r['ot']:>2}  {r['pts']:>3}"
        )
        out.append(line)
        if r["rank"] == 3:
            out.append("-------")
    return "\n".join(out)

# ====== —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ ======
def build_message() -> str:
    today = dt.datetime.now(tz=TZ).date()

    cur = fetch_nhl_standings_by_division()
    prev = load_prev_positions()

    # —Ç—Ä–µ–Ω–¥ –ø–æ –∫–∞–∂–¥–æ–º—É –¥–∏–≤–∏–∑–∏–æ–Ω—É
    east_divs = {}
    for d in CONF_DIV_ORDER["east"]:
        east_divs[d] = attach_trend_div(cur["east"].get(d, []), (prev["divisions"].get(d) or {}))
    west_divs = {}
    for d in CONF_DIV_ORDER["west"]:
        west_divs[d] = attach_trend_div(cur["west"].get(d, []), (prev["divisions"].get(d) or {}))

    # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ¬´—Å–µ–≥–æ–¥–Ω—è¬ª –∫–∞–∫ ¬´–≤—á–µ—Ä–∞¬ª –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫
    all_divs = {**east_divs, **west_divs}
    save_current_as_prev(today, all_divs)

    head = f"<b>–ù–•–õ ¬∑ –¢–∞–±–ª–∏—Ü–∞ –ø–æ –¥–∏–≤–∏–∑–∏–æ–Ω–∞–º</b> ‚Äî {today.strftime(DATE_FMT)}"
    info = "‚ÑπÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫: ESPN JSON (level=3 ‚Äî –¥–∏–≤–∏–∑–∏–æ–Ω—ã). –°—Ä–∞–≤–Ω–µ–Ω–∏–µ ‚Äî —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–æ—Å—Ç–∞ (–ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª)."

    east_block = "\n\n".join([
        fmt_division(f"–í–æ—Å—Ç–æ–∫ ‚Äî {DIV_RU['Atlantic']}", east_divs["Atlantic"]),
        fmt_division(f"–í–æ—Å—Ç–æ–∫ ‚Äî {DIV_RU['Metropolitan']}", east_divs["Metropolitan"]),
    ])
    west_block = "\n\n".join([
        fmt_division(f"–ó–∞–ø–∞–¥ ‚Äî {DIV_RU['Central']}", west_divs["Central"]),
        fmt_division(f"–ó–∞–ø–∞–¥ ‚Äî {DIV_RU['Pacific']}", west_divs["Pacific"]),
    ])

    return "\n\n".join([head, east_block, "", west_block, "", info])

def send_telegram(text: str):
    if not (BOT_TOKEN and CHAT_ID):
        print("No TELEGRAM_BOT_TOKEN/CHAT_ID in env", file=sys.stderr)
        return
    r = SESSION.post(
        f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
        json={"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML", "disable_web_page_preview": True},
        timeout=25
    )
    r.raise_for_status()

if __name__ == "__main__":
    try:
        msg = build_message()
        send_telegram(msg)
        print("OK")
    except Exception as e:
        print("ERROR:", repr(e), file=sys.stderr)
        sys.exit(1)
